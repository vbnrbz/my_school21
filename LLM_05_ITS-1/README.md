# Большая языковая модель (LLM)
Аннотация: В этом проекте ты научишься работать с большими языковыми моделями (LLM) и применишь их для саммаризации научных статей. 

## Содержание
1. [Chapter I](#chapter-i)  
   - [Рекомендации к проекту](#рекомендации-к-проекту)
2. [Chapter II](#chapter-ii)   
   - [Задание 1: Подключение языковой модели](#задание-1-подключение-языковой-модели)  
   - [Задание 2: Скачивание статей](#задание-2-скачивание-статей)  
   - [Задание 3: Саммаризация статьи](#задание-3-саммаризация-статьи)  
   - [Задание 4: Консольное приложение](#задание-4-консольное-приложение)


## Введение 
Каждое утро в нашем заведении начинается одинаково — это уже обычай, традиция, ритуал. Конечно же, речь идет о проверке почты, никак иное письмо от главврача.
>>**Стажер**

> Ты когда-нибудь мечтал стать лучшей версией себя?\
> Умнее, технологичнее, прокачаннее… \
> Всего один шаг вступления в лабораторию разблокирует тебя и запустит IT-процессы в медицине, а также создаст другую версию тебя.

> Привет, стажер!\
> Отправлю тебе новый проект, где основная цель проекта — работать с большими языковыми моделями (LLM) и применять их для саммаризации научных статей. В процессе выполнения тебе необходимо подключить языковую модель через API, загрузить текст научной статьи, создать класс для саммаризации текста и реализовать консольное приложение, позволяющее получать краткое содержание статьи по ссылке.\
> Все подробности ниже. Удачи!

> С наилучшими пожеланиями,\
> заведующий (кафедры) IT-кластера.
>>**Главврач**


## Chapter I
### Рекомендации к проекту
Как учиться в «Школе 21»:  
- На протяжении всего курса ты будешь самостоятельно добывать информацию. Пользуйся всеми доступными средствами поиска информации, к примеру, Google и GigaChat. Будь внимателен к источникам информации: проверяй, думай, анализируй, сравнивай. 
- Взаимообучение (P2P, Peer-to-Peer) — это процесс, при котором учащиеся обмениваются знаниями и опытом, выступая одновременно в роли учителей и учеников. Этот подход позволяет учиться не только у преподавателя, но и друг у друга, что способствует более глубокому пониманию материала.
- Не стесняйся просить помощи: вокруг тебя такие же пиры, которые тоже проходят этот путь впервые. Не бойся откликаться на просьбы о помощи. Твой опыт ценен и полезен, смело делись им с другими участниками. 
- Не списывай, а если пользуешься помощью — всегда разбирайся до конца, почему, как и зачем. Иначе твое обучение не будет иметь никакого смысла. 
- Если ты на чем-то застрял, и кажется, что ты уже все перепробовал, но все равно непонятно, куда идти, — просто передохни! Поверь, этот совет помогал многим разработчикам в их работе. Проветрись, перезагрузи голову и, возможно, в следующий раз тебе наконец придет нужное решение!
- Важен не только результат обучения, но и сам процесс. Нужно не просто решить задачу, а понять, КАК ее решить.

Как работать с проектом: 
- Вся работа выполняется на виртуальной машине. Для начала ее нужно настроить, воспользовавшись [инструкцией](https://applicant.21-school.ru/guide_vm_med). Далее запустить виртуальную машину и продолжать выполнять работу над проектом там.
- Перед выполнением проект необходимо склонировать с GitLab в одноименный репозиторий.
- Все файлы с кодом необходимо создавать в папке `src` склонированного репозитория.
- После клонирования проекта необходимо создать ветку `develop` и вести разработку в ней. После этого пушить в GitLab также нужно ветку `develop`.
- В твоей директории не должно быть иных файлов, кроме тех, что обозначены в заданиях.

Дисклеймер: 
- Наша команда не медики. Если ты будешь видеть в тексте медицинские неточности или ошибки, заранее просим у тебя прощения. Оставляй нам обратную связь, и мы все поправим!
- Иногда повествование ведется в несколько шутливой форме, чтобы не было скучно. Однако, как ты и сам знаешь, юмор и шутки — субъективная вещь. Поэтому если каламбуры в данном тексте, по твоему мнению, попахивают батиным юмором, то, пожалуйста, просто прими это.

## Chapter II
## Саммаризация научных статей с использованием больших языковых моделей (LLM)

### Задание 1: Подключение языковой модели

В современном мире языковые модели стали следующей ступенью автоматизации процессов. Они позволяют очень быстро автоматизировать интеллектуальные задачи. К одной из таких задач относится написание краткого содержания к текстам. Создание краткого содержания называется саммаризацией, а само краткое содержание — саммари (англ. summary). В данном проекте тебе предстоит подключить языковую модель и настроить ее на создание краткого содержания текстов научных статей.

Для знакомства с языковыми моделями будем использовать языковую модель Gigachat от Сбера. Сама модель представляет из себя очень большую и глубокую нейросеть, которая обучена на работу с текстом. Но ты будешь пользоваться АПИ к этой модели.

- Создай файл `ai_gigachat.py`, в нем веди всю работу по первому заданию.
- Изучи API Gigachat. Создай функцию `connect_gigachat` для подключения к API языковой модели.
- Реализуй функцию `ask_gigachat`, которая принимает текст, отправляет его в языковую модель и возвращает её ответ.
- Изучи концепцию промпт-инжиниринга, создай простой промпт и отправь его в модель для получения ответа.

Получившиеся функции и пример сохрани в файл `ai_gigachat.py`.

### Задание 2: Скачивание статей

В качестве источника статей в этом проекте мы будем использовать журнал `arxiv.org`. В нем публикуется огромное число публичных статей. Журнал очень популярный, и существует множество инструментов для получения данных оттуда.

- Создай файл `article.py`, в нем веди всю работу по этому заданию.
- Напиши функцию `article_to_text(link) -> str`, которая принимает ссылку на статью с `arxiv.org` и возвращает текст статьи в формате строки.
- В случае недоступности ссылки создай ошибку `NotAvailable` и выбрасывай эту ошибку из функции.
- В коде используй функцию на одном примере, удостоверься, что все работает корректно.

Функцию и пример сохрани в файл `article.py`.

### Задание 3: Саммаризация статьи

Наконец, мы можем совместить результаты для саммаризации и перевода статей. Благодаря большим языковым моделям нам доступно огромное число возможностей работы с текстом. В данном случае ты будешь делать краткое содержание статьи с языка оригинала на русский язык.

- Создай файл `summarizer.py`, в нем веди всю работу по данному заданию.
- Создай класс `Summarizer`:
  - В конструкторе подключайся к языковой модели.
  - Реализуй приватный метод `__article_to_text(link) -> str` для загрузки текста статьи.
  - Реализуй приватный метод `__send_gigachat(text) -> str` для отправки текста в Gigachat и получения ответа.
  - Реализуй публичный метод `summarize(link) -> str`, который возвращает краткое содержание статьи, загружая текст и отправляя его в модель с промптом для саммаризации. 
- Продемонстрируй работу на одном примере в этом же файле.

Результатом задания будет файл `summarizer.py` со всем необходимым по заданию кодом.

Рекомендация: самая важная деталь, влияющая на качество работы модели, — правильный промпт. Существуют целые подборки для промптинга. Также существуют промпты для создания промптов. В общем, это наиважнейшая деталь при работе с большими языковыми моделями. Поэтому стоит попробовать несколько вариантов и подумать, как можно улучшить промпт, чтобы добиться наилучшего качества.

### Задание 4: Консольное приложение

Использовать скрипт не всегда удобно, и на помощь приходят пользовательские интерфейсы. Для простоты разработки и использования сделай интерфейс командной строки. Он будет принимать на вход ссылку на статью и выводить в консоль краткое содержание статьи в виде текста.

- Реализуй скрипт `summary.py`, который принимает ссылку на статью через аргумент командной строки.
- Скрипт должен выводить краткое содержание статьи в консоль.
- Если возникла какая-либо ошибка, запиши ошибку в консоль.

Результатом работы будет скрипт:
```bash
python summary.py https://arxiv.org/abs/2005.14165
```

💡 [Нажми сюда](http://opros.so/jSVV1), **чтобы поделиться с нами обратной связью на этот проект**. Это анонимно и поможет команде Продукта сделать твоё обучение лучше.